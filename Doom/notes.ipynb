{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### My notes\n",
    "There are six action moves wasd, turn lr, attack \n",
    "**Couldn't download the doom app from the course, so I downloaded vizdoom**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "488dea2e69e01e4f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-12T14:51:32.936799800Z",
     "start_time": "2023-10-12T14:51:27.971152400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import gym\n",
    "import vizdoom as vzd\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "# import experience_replay, image_preprocessing                                 \n",
    "# Part 1 - Building the AI\n",
    "\n",
    "# Making the brain\n",
    "class CNN(nn.Module): # The input_image is (1x80x80)\n",
    "    def __init__(self, number_actions, ):\n",
    "        super(CNN, self).__init__()\n",
    "        self.convolutional1 = nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=5, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3,2),\n",
    "        )      \n",
    "        torch.nn.init.xavier_normal_(self.convolutional1.weight)\n",
    "        # self.convolutional1.apply(init_cnn)\n",
    "        self.convolutional2 = nn.Sequential(\n",
    "            nn.Conv2d(32,32,kernel_size=3, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3,2),\n",
    "        )         \n",
    "        torch.nn.init.xavier_normal_(self.convolutional2.weight)\n",
    "\n",
    "        self.convolutional3 = nn.Sequential(\n",
    "            nn.Conv2d(32,64,kernel_size=2, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3,2)\n",
    "        )\n",
    "        torch.nn.init.xavier_normal_(self.convolutional3.weight)\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(self.count_neurons((1, 80, 80)), out_features=40),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        torch.nn.init.xavier_normal_(self.convolutional3.weight)\n",
    "        # self.fc1 = nn.Sequential(nn.Linear(out_features=40), nn.Dropout(), nn.ReLU())\n",
    "        self.fc2 = nn.Linear(40, number_actions)\n",
    "        \n",
    "        # self.apply_init(init_cnn) # make weights xavier_uniform\n",
    "        \n",
    "    def count_neurons(self, image_dim): # If we don't use LazyLinear\n",
    "        x = Variable(torch.rand(1, *image_dim))\n",
    "        # kernel = 3, stride = 2\n",
    "        x = self.convolutional1(x)\n",
    "        x = self.convolutional2(x)\n",
    "        x = self.convolutional3(x)\n",
    "        # return x.data.view(1,-1).size(1)\n",
    "        return x.data.view(1, -1, antialias=True).size(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.convolutional1(x)\n",
    "        x = self.convolutional2(x)\n",
    "        x = self.convolutional3(x)\n",
    "        x = x.view(x.size(0),-1, antialias=True)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    # def apply_init(self, inputs, init=None):\n",
    "    #     self.forward(*inputs)\n",
    "    #     if init is not None:\n",
    "    #         self.net.apply(init)\n",
    "\n",
    "# Making the body\n",
    "\n",
    "# Making the AI"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now a check that the cnn works\n",
    "* We see that the accuracy is the accuracy of a LeNet, so it may be better to upgrade the cnn later for better results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d728f925a8370157"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torch.cuda\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def load_mnist(batch_size=128, resize=(80, 80)):\n",
    "    # Load the FashionMNIST dataset\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,)), transforms.Resize(resize)])\n",
    "    train_dataset = FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "    test_dataset = FashionMNIST(root='./data', train=False, transform=transform)\n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "def init_cnn(module):\n",
    "    if type(module) == nn.Linear or type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform_(module.weight)\n",
    "\n",
    "\n",
    "def fit(model: nn.Module, train_loader: DataLoader):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    model = model.to(device)\n",
    "    input_data = next(iter(train_loader))[0].to(device)\n",
    "    # model.apply_init([input_data], init_cnn)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), 0.001)\n",
    "\n",
    "    total_step = len(train_loader)\n",
    "    for epoch in range(10):\n",
    "        epoch_loss = 0.0\n",
    "        for i, (images, labels) in tqdm(enumerate(train_loader), total=total_step):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # Print average epoch loss\n",
    "        average_loss = epoch_loss / total_step\n",
    "        print(f\"Epoch [{epoch + 1}/10], Average Loss: {average_loss:.4f}\")\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T14:51:33.402336800Z",
     "start_time": "2023-10-12T14:51:32.945798900Z"
    }
   },
   "id": "c0e5a72b9b0adf52"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosti_0b5rpb8\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc483300f185489bb30cbb6468540ce6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 0.8105\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a2cc6e0b1b9f4126bb72718e6154ac09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Average Loss: 0.5635\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f192ba9364fc44f3bc1b4d92ba8eb579"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Average Loss: 0.5053\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9827db06682d448bb27683caa4b0e255"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Average Loss: 0.4721\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f69837ade40f4436a6fd1394ce676f59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Average Loss: 0.4467\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "516ee5b8cf5542cfbb35c1100c655232"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Average Loss: 0.4291\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "393e6750215b417eac8d8ef97ed0cc3b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Average Loss: 0.4145\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6d4cec1b7e35499984b2e02b57b56af6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Average Loss: 0.4002\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e82dde12446845d5aed52911bb045319"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Average Loss: 0.3910\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "325472d6378243a9b926b57de6dcaaf9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Average Loss: 0.3847\n"
     ]
    }
   ],
   "source": [
    "train_loader, _ = load_mnist()\n",
    "model = fit(CNN(10), train_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6dc33888e2603390"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now making the body"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8eb7fbf8b21007c4"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class SoftmaxBody(nn.Module):\n",
    "    \n",
    "    def __init__(self, T):\n",
    "        super(SoftmaxBody, self).__init__()\n",
    "        self.T = T\n",
    "        \n",
    "    def forward(self, outputs):\n",
    "        # to get the action, we use softmax\n",
    "        probs = F.softmax(outputs * self.T)\n",
    "        actions = probs.multinomial()\n",
    "        return actions\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T14:51:34.100836900Z",
     "start_time": "2023-10-12T14:51:34.082838800Z"
    }
   },
   "id": "8e849f5d2c63c326"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Now create the AI by combining body and brain "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c21b3d215842a8f9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class AI:\n",
    "    def __init__(self, brain: CNN, body: SoftmaxBody):\n",
    "        self.brain = brain\n",
    "        self.body = body\n",
    "        \n",
    "    # The combination of the forward functions\n",
    "    def __call__(self, inputs): # with __call__ you can treat an AI object as a function\n",
    "        inp = Variable(torch.from_numpy(np.array(inputs, dtype=np.float32)))\n",
    "        output = self.brain(inp)\n",
    "        actions = self.body(output)\n",
    "        return actions.data.numpy()     # tensor to array\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T14:51:34.938844400Z",
     "start_time": "2023-10-12T14:51:34.932041500Z"
    }
   },
   "id": "e5f7a5262c2bb813"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "743a32d1e6b52eb2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Attempting to run vizdoom by the GitHub example"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49d82f33060a95e0"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "('C:\\\\Users\\\\kosti_0b5rpb8\\\\anaconda3\\\\envs\\\\torch_cuda__118\\\\lib\\\\site-packages\\\\vizdoom\\\\scenarios',\n ['basic.cfg',\n  'basic.wad',\n  'cig.cfg',\n  'cig.wad',\n  'cig_with_unknown.wad',\n  'deadly_corridor.cfg',\n  'deadly_corridor.wad',\n  'deathmatch.cfg',\n  'deathmatch.wad',\n  'defend_the_center.cfg',\n  'defend_the_center.wad',\n  'defend_the_line.cfg',\n  'defend_the_line.wad',\n  'health_gathering.cfg',\n  'health_gathering.wad',\n  'health_gathering_supreme.cfg',\n  'health_gathering_supreme.wad',\n  'learning.cfg',\n  'multi.cfg',\n  'multi_deathmatch.wad',\n  'multi_duel.cfg',\n  'multi_duel.wad',\n  'my_way_home.cfg',\n  'my_way_home.wad',\n  'oblige.cfg',\n  'predict_position.cfg',\n  'predict_position.wad',\n  'rocket_basic.cfg',\n  'rocket_basic.wad',\n  'simpler_basic.cfg',\n  'simpler_basic.wad',\n  'take_cover.cfg',\n  'take_cover.wad'])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "vzd.scenarios_path, os.listdir(vzd.scenarios_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T14:51:36.700625400Z",
     "start_time": "2023-10-12T14:51:36.684126400Z"
    }
   },
   "id": "93dfb0ea04a2cdf6"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# First try to make the environment for doom\n",
    "# The problem is that the one that the course shows I cannot get, so I have to learn to use vizdoom\n",
    "import os \n",
    "from tqdm import trange\n",
    "import itertools as it\n",
    "config_file_path = os.path.join(vzd.scenarios_path, 'simpler_basic.cfg')\n",
    "# config_file_path = os.path.join(vzd.scenarios_path, \"rocket_basic.cfg\")\n",
    "# config_file_path = os.path.join(vzd.scenarios_path, \"basic.cfg\")\n",
    "# use GPU if available (don't really know what this does.\n",
    "import torchvision\n",
    "torch.backends.cudnn.benchmark = True \n",
    "from time import time, sleep\n",
    "from PIL import Image\n",
    "\n",
    "resolution = (80, 80)   # in example was (30, 45)\n",
    "def preprocess(img):\n",
    "    \"\"\"Down samples image to resolution\"\"\"\n",
    "    \n",
    "    img = Image.fromarray(img)\n",
    "    img = torchvision.transforms.Resize(resolution)(img)\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    # img = img.numpy().astype(np.float32)\n",
    "    img = np.expand_dims(img, axis=0) # for the batch dim\n",
    "    return img\n",
    "\n",
    "def create_simple_game():\n",
    "    print(\"Initializing doom...\")\n",
    "    game = vzd.DoomGame()\n",
    "    game.load_config(config_file_path)\n",
    "    game.set_window_visible(False) # maybe change this afterward\n",
    "    game.set_mode(vzd.Mode.PLAYER)\n",
    "    game.set_screen_format(vzd.ScreenFormat.GRAY8)\n",
    "    game.set_screen_resolution(vzd.ScreenResolution.RES_640X480)\n",
    "    game.init()\n",
    "    print(\"Doom initialized.\")\n",
    "    \n",
    "    return game\n",
    "\n",
    "# Training regime\n",
    "test_episodes_per_epoch = 100\n",
    "# Other parameters\n",
    "frame_repeat = 12\n",
    "\n",
    "model_savefile = \"./model-doom.pth\"\n",
    "save_model = True\n",
    "load_model = False\n",
    "skip_learning = False\n",
    "\n",
    "def test(game, agent):\n",
    "    \"\"\"Runs a test_episodes_per_epoch episodes and prints the result\"\"\"\n",
    "    print('\\nTesting...')\n",
    "    test_scores = []\n",
    "    for test_episode in trange(test_episodes_per_epoch, leave=False):\n",
    "        game.new_episode()\n",
    "        while not game.is_episode_finished():\n",
    "            state = preprocess(game.get_state().screen_buffer)\n",
    "            best_action_index = agent.get_action(state)\n",
    "            \n",
    "            game.make_action(actions[best_action_index], frame_repeat)\n",
    "        r = game.get_total_reward()\n",
    "        test_scores.append(r)\n",
    "    \n",
    "    test_scores = np.array(test_scores)\n",
    "    \n",
    "    print(\n",
    "        \"Results: mean: {:.1f} +/- {:.1f},\".format(\n",
    "            test_scores.mean(), test_scores.std()\n",
    "        ),\n",
    "        \"min: %.1f\" % test_scores.min(),\n",
    "        \"max: %.1f\" % test_scores.max(),\n",
    "    )\n",
    "    \n",
    "\n",
    "def run(game, agent, actions, num_epochs, frame_repeat, steps_per_epoch=2000):\n",
    "    \"\"\" Run num epochs of training episodes.\n",
    "     Skip frame_repeat number of frames after each action. \"\"\"\n",
    "    start_time = time()\n",
    "    for epoch in range(num_epochs):\n",
    "        game.new_episode()\n",
    "        train_scores = []\n",
    "        global_step = 0\n",
    "        print(\"\\nEpoch #\" + str(epoch + 1))\n",
    "        \n",
    "        for _ in trange(steps_per_epoch, leave=False):\n",
    "            state = preprocess(game.get_state().screen_buffer)\n",
    "            action = agent.get_action(state)\n",
    "            reward = game.make_action(actions[action], frame_repeat)\n",
    "            done = game.is_episode_finished()\n",
    "            \n",
    "            if not done:\n",
    "                next_state = preprocess(game.get_state().screen_buffer)\n",
    "            else:\n",
    "                next_state = np.zeros((1,80,80)).astype(np.float32)     # in the original was (1, 30, 45)\n",
    "            \n",
    "            agent.append_memory(state, action, reward, next_state, done)\n",
    "            \n",
    "            if global_step > agent.batch_size:\n",
    "                agent.train()\n",
    "                \n",
    "            if done:\n",
    "                train_scores.append(game.get_total_reward())\n",
    "                game.new_episode()\n",
    "            \n",
    "            global_step += 1\n",
    "            \n",
    "        agent.update_target_net()\n",
    "        train_scores = np.array(train_scores)\n",
    "        \n",
    "        print(\n",
    "            \"Results: mean: {:.1f} +/- {:.1f},\".format(\n",
    "                train_scores.mean(), train_scores.std()\n",
    "            ),\n",
    "            \"min: %.1f,\" % train_scores.min(),\n",
    "            \"max: %.1f,\" % train_scores.max(),\n",
    "        )\n",
    "        \n",
    "        test(game, agent)\n",
    "        if save_model:\n",
    "            print(\"Saving the network weights to: \", model_savefile)\n",
    "            torch.save(agent.q_net, model_savefile)\n",
    "        print(\"Total elapsed time: %.2f minutes\" % ((time() - start_time) / 60.0))\n",
    "        \n",
    "        game.close()\n",
    "        return agent, game\n",
    "    \n",
    "# todo Check the Rainbow algo\n",
    "class DuelQNet(nn.Module):\n",
    "    \"\"\"Single stream with two outputs \n",
    "    one for State Values V_π(s) = E[Q_π(s,a)] for a~π(s) -> (LongTerm) \n",
    "    one for Advantage A_π(s,a) = Q_π(s,a) - V_π(s)\n",
    "    The final Q value is:\n",
    "    Q(s,a; θ,β,γ) = V(s;θ,γ) + Α(s,a;θ,β), where θ,β,γ are the trained weights\n",
    "    \"\"\"\n",
    "    def __init__(self, available_actions_count):\n",
    "        # todo this guy used stride of 2 and not MaxPooling... Also the guy had 8 instead of 32 and 16 instead of 64\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        torch.nn.init.xavier_normal_(self.conv1[0].weight)\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        torch.nn.init.xavier_normal_(self.conv2[0].weight)\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        torch.nn.init.xavier_normal_(self.conv3[0].weight)\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        torch.nn.init.xavier_normal_(self.conv4[0].weight)\n",
    "        \n",
    "        # self.state_fc = nn.Sequential(nn.Linear(self.count_neurons((1, 80, 80)), out_features=64), nn.ReLU(), nn.Linear(64, 1))\n",
    "        self.state_fc = nn.Sequential(nn.LazyLinear(64), nn.ReLU(), nn.Linear(64, 1))\n",
    "        \n",
    "        # self.advantage_fc = nn.Sequential(nn.Linear(self.count_neurons((1, 80, 80)), 64), nn.ReLU(), nn.Linear(64, available_actions_count))\n",
    "        self.advantage_fc = nn.Sequential(nn.LazyLinear(64), nn.ReLU(), nn.Linear(64, available_actions_count))\n",
    "    \n",
    "    def count_neurons(self, image_dim): # If we don't use LazyLinear\n",
    "        device = 'cuda'\n",
    "        x = Variable(torch.rand(1, *image_dim).to(device))\n",
    "        # kernel = 3, stride = 2\n",
    "        x = self.conv1(x).to(device)\n",
    "        x = self.conv2(x).to(device)\n",
    "        x = self.conv3(x).to(device)\n",
    "        x = self.conv4(x).to(device)\n",
    "        # return x.data.view(1,-1).size(1)\n",
    "        return x.data.view(1, -1).size(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv_output_size = self.count_neurons((1,80,80))\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = x.view(-1, conv_output_size)\n",
    "        x1 = x[:, :(conv_output_size //2)]\n",
    "        x2 = x[:, (conv_output_size //2):]\n",
    "        state_value = self.state_fc(x1).reshape(-1,1)\n",
    "        advantage_values = self.advantage_fc(x2)\n",
    "        x = (state_value + \n",
    "             (advantage_values - advantage_values.mean(dim=1).reshape(-1,1))) # Note that while subtracting the mean in equation helps with identifiability (1-1)\n",
    "        return x\n",
    "            \n",
    "            \n",
    "# if __name__ == '__main__':\n",
    "#     game = create_simple_game()\n",
    "#     n = game.get_available_buttons_size()\n",
    "#     actions = [list(a) for a in it.product([0, 1], repeat=n)]\n",
    "#     print(actions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T14:54:27.842582600Z",
     "start_time": "2023-10-12T14:54:27.813574900Z"
    }
   },
   "id": "829a1d07c62f99a4"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosti_0b5rpb8\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e7cd1cf9d554729815fd8238b21731e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 0.3944\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8279de7fd5af4820986a26ccddb34929"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Average Loss: 0.2560\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a872fbfd23f2436bb9f6316584747127"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Average Loss: 0.2064\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43aee60d86e14aedb5802029525d4ba1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Average Loss: 0.1715\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4eaaa6f1dc8649a3945cd6a6255aa67f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Average Loss: 0.1447\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73ddd2da591b4c35a9e4efe3b3a5e331"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Average Loss: 0.1188\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b912d5521865458081a1a29d382a67ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Average Loss: 0.0969\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c5c68b0eb8e4cd2b9691031487f8975"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Average Loss: 0.0818\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "324bfd983fc145698fc1d6c71bf49750"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Average Loss: 0.0740\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/469 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e46d90ec70e344ef80f484e43660b358"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Average Loss: 0.0642\n"
     ]
    }
   ],
   "source": [
    "train_loader, _ = load_mnist()\n",
    "new_model = fit(DuelQNet(10), train_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T15:03:49.233487900Z",
     "start_time": "2023-10-12T14:54:28.876339600Z"
    }
   },
   "id": "871e54294824d3ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we know that the Duel DQN works, we can make the agent"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3138ad5884e05c30"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random \n",
    "\n",
    "class DQNAgent:  # with epsilon (adaptive)-> descending selection policy\n",
    "    \"\"\"\n",
    "    :var target_net: This likely represents a target neural network, which is a copy of the primary Q-network.\n",
    "         The target network is typically used to stabilize the training process, as it helps prevent the learning\n",
    "          process from being overly influenced by changes in the Q-network's weights during training.\n",
    "    :var self.q_net: This is the primary Q-network, which is the network that is actively being trained \n",
    "        and updated during the reinforcement learning process\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            action_size,\n",
    "            memory_size,\n",
    "            batch_size,\n",
    "            discount_factor,\n",
    "            lr,\n",
    "            load_model,\n",
    "            epsilon=1,\n",
    "            epsilon_decay=0.9996,\n",
    "            epsilon_min=0.1,\n",
    "    ):\n",
    "        self.action_size = action_size\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.batch_size = batch_size\n",
    "        self.discount = discount_factor\n",
    "        self.lr = lr\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        if load_model:\n",
    "            print(\"Loading model from: \", model_savefile)\n",
    "            # Single Stream so q_net === target_net\n",
    "            self.q_net = torch.load(model_savefile)\n",
    "            self.target_net = torch.load(model_savefile)\n",
    "            self.epsilon = self.epsilon_min\n",
    "            \n",
    "        else:\n",
    "            print(\"Initializing new model\")\n",
    "            self.q_net = DuelQNet(action_size).to(device)\n",
    "            self.target_net = DuelQNet(action_size).to(device)\n",
    "        \n",
    "        self.opt = optim.SGD(self.q_net.parameters(), lr=self.lr) # todo maybe use Adam\n",
    "        \n",
    "    def get_action(self, state):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param state: \n",
    "        :return: \n",
    "        \"\"\"\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            return random.choice(range(self.action_size))\n",
    "        else:\n",
    "            state = np.expand_dims(state, axis=0)   # add batch dim\n",
    "            state = torch.from_numpy(state).float().to(device)\n",
    "            action = torch.argmax(self.q_net(state)).item()\n",
    "            return action\n",
    "        \n",
    "    def update_target_net(self): # target net(ground truth) lags a bit to provide stability\n",
    "        self.target_net.load_state_dict(self.q_net.state_dict())\n",
    "        \n",
    "    def append_memory(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def train(self): # what does this train do? is it the play one?\n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        batch = np.array(batch, dtype=object)\n",
    "        \n",
    "        states = np.stack(batch[:, 0]).astype(float)\n",
    "        actions = batch[:, 1].astype(int)\n",
    "        rewards = batch[:, 2].astype(float)\n",
    "        next_states = np.stack(batch[:, 3]).astype(float)\n",
    "        dones = batch[:, 4].astype(bool)\n",
    "        not_dones = ~dones\n",
    "        \n",
    "        row_idx = np.arange(self.batch_size)    # used for indexing the batch\n",
    "        \n",
    "        # value of the next states with double q learning\n",
    "        with torch.no_grad():\n",
    "            next_states = torch.from_numpy(next_states).float().to(device)\n",
    "            idx = row_idx, np.argmax(self.q_net(next_states).cpu().data.numpy(), 1)\n",
    "            next_state_values = self.target_net(next_states).cpu().data.numpy()[idx]\n",
    "            next_state_values = next_state_values[not_dones]\n",
    "            \n",
    "        # this defines y = r + discount * max_a q(s', a)\n",
    "        q_targets = rewards.copy()\n",
    "        q_targets[not_dones] += self.discount * next_state_values\n",
    "        q_targets = torch.from_numpy(q_targets).float().to(device)\n",
    "        \n",
    "        # this selects only the q values of the actions taken\n",
    "        idx = row_idx, actions\n",
    "        states = torch.from_numpy(states).float().to(device)\n",
    "        action_values = self.q_net(states)[idx].float().to(device)\n",
    "        \n",
    "        # todo here in the tutorial would use the Variable thing from torch\n",
    "        self.opt.zero_grad()  \n",
    "        td_error = self.criterion(q_targets, action_values)\n",
    "        td_error.backward()\n",
    "        self.opt.step()\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        else:\n",
    "            self.epsilon = self.epsilon_min\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T15:03:49.295170700Z",
     "start_time": "2023-10-12T15:03:49.286760Z"
    }
   },
   "id": "21d836cdc7ea5d12"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing doom...\n",
      "Doom initialized.\n",
      "Initializing new model\n",
      "\n",
      "Epoch #1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: mean: -19.1 +/- 153.5, min: -380.0, max: 95.0,\n",
      "\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: mean: -0.5 +/- 143.3, min: -355.0 max: 95.0\n",
      "Saving the network weights to:  ./model-doom.pth\n",
      "Total elapsed time: 4.15 minutes\n",
      "Total score:  94.0\n",
      "Total score:  94.0\n",
      "Total score:  94.0\n"
     ]
    },
    {
     "ename": "ViZDoomUnexpectedExitException",
     "evalue": "Controlled ViZDoom instance exited unexpectedly.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mViZDoomUnexpectedExitException\u001B[0m            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 55\u001B[0m\n\u001B[0;32m     53\u001B[0m     game\u001B[38;5;241m.\u001B[39mset_action(actions[best_action_index])\n\u001B[0;32m     54\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(frame_repeat):\n\u001B[1;32m---> 55\u001B[0m         \u001B[43mgame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madvance_action\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;66;03m# Sleep between episodes\u001B[39;00m\n\u001B[0;32m     58\u001B[0m sleep(\u001B[38;5;241m1.0\u001B[39m)\n",
      "\u001B[1;31mViZDoomUnexpectedExitException\u001B[0m: Controlled ViZDoom instance exited unexpectedly."
     ]
    }
   ],
   "source": [
    "# Q-learning settings\n",
    "learning_rate = 0.00025\n",
    "discount_factor = 0.99\n",
    "train_epochs = 5\n",
    "learning_steps_per_epoch = 2000\n",
    "replay_memory_size = 10000\n",
    "\n",
    "# NN learning settings\n",
    "batch_size = 64\n",
    "\n",
    "episodes_to_watch = 10\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Initialize game and actions\n",
    "    game = create_simple_game()\n",
    "    n = game.get_available_buttons_size()\n",
    "    actions = [list(a) for a in it.product([0, 1], repeat=n)]\n",
    "    \n",
    "    # Initialize our agent with the set parameters\n",
    "    agent = DQNAgent(\n",
    "        len(actions),\n",
    "        lr=learning_rate,\n",
    "        batch_size=batch_size,\n",
    "        memory_size = replay_memory_size,\n",
    "        discount_factor=discount_factor,\n",
    "        load_model=load_model,\n",
    "    )\n",
    "    \n",
    "    # Run the training for the set number of epochs\n",
    "    if not skip_learning:\n",
    "        agent, game = run(\n",
    "            game,\n",
    "            agent,\n",
    "            actions,\n",
    "            num_epochs=train_epochs,\n",
    "            frame_repeat=frame_repeat,\n",
    "            steps_per_epoch=learning_steps_per_epoch,\n",
    "        )\n",
    "        \n",
    "    # Reinitialize the game with a window visible\n",
    "    game.close()\n",
    "    game.set_window_visible(True)\n",
    "    game.set_mode(vzd.Mode.ASYNC_PLAYER)\n",
    "    game.init()\n",
    "    \n",
    "    for _ in range(episodes_to_watch):\n",
    "        game.new_episode()\n",
    "        while not game.is_episode_finished():\n",
    "            state = preprocess(game.get_state().screen_buffer)\n",
    "            best_action_index = agent.get_action(state)\n",
    "            \n",
    "            # Instead of make_action(a, frame_repeat) in order to make the animation smooth\n",
    "            game.set_action(actions[best_action_index])\n",
    "            for _ in range(frame_repeat):\n",
    "                game.advance_action()\n",
    "                \n",
    "        # Sleep between episodes\n",
    "        sleep(1.0)\n",
    "        score = game.get_total_reward()\n",
    "        print(\"Total score: \", score)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T15:08:07.098366800Z",
     "start_time": "2023-10-12T15:03:49.300730Z"
    }
   },
   "id": "e6baf5ab5e0ace7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Now making the one from the Course because I learned how to use gym"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fd29a8b10249f0c"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosti_0b5rpb8\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\vizdoom\\gym_wrapper\\base_gym_env.py:79: UserWarning: Detected screen format CRCGCB. Only RGB24 and GRAY8 are supported in the Gym wrapper. Forcing RGB24.\n",
      "  warnings.warn(\n",
      "C:\\Users\\kosti_0b5rpb8\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\gym\\wrappers\\record_video.py:75: UserWarning: \u001B[33mWARN: Overwriting existing videos at C:\\Users\\kosti_0b5rpb8\\Desktop\\Reinforcement_Learning_python_applications\\Doom\\videos\\doom.mp4 folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001B[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 20\u001B[0m\n\u001B[0;32m     17\u001B[0m number_actions \u001B[38;5;241m=\u001B[39m doom_env\u001B[38;5;241m.\u001B[39maction_space\u001B[38;5;241m.\u001B[39mn\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Building the AI\u001B[39;00m\n\u001B[1;32m---> 20\u001B[0m cnn \u001B[38;5;241m=\u001B[39m \u001B[43mCNN\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnumber_actions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     21\u001B[0m softmax_body \u001B[38;5;241m=\u001B[39m SoftmaxBody(T \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m)\n\u001B[0;32m     23\u001B[0m ai \u001B[38;5;241m=\u001B[39m AI(brain\u001B[38;5;241m=\u001B[39mcnn, body\u001B[38;5;241m=\u001B[39msoftmax_body)\n",
      "Cell \u001B[1;32mIn[2], line 30\u001B[0m, in \u001B[0;36mCNN.__init__\u001B[1;34m(self, number_actions)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28msuper\u001B[39m(CNN, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m()\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvolutional1 \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(\n\u001B[0;32m     25\u001B[0m     nn\u001B[38;5;241m.\u001B[39mConv2d(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m32\u001B[39m,kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, stride\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[0;32m     26\u001B[0m     nn\u001B[38;5;241m.\u001B[39mBatchNorm2d(\u001B[38;5;241m32\u001B[39m),\n\u001B[0;32m     27\u001B[0m     nn\u001B[38;5;241m.\u001B[39mReLU(),\n\u001B[0;32m     28\u001B[0m     nn\u001B[38;5;241m.\u001B[39mMaxPool2d(\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m2\u001B[39m),\n\u001B[0;32m     29\u001B[0m )      \n\u001B[1;32m---> 30\u001B[0m torch\u001B[38;5;241m.\u001B[39mnn\u001B[38;5;241m.\u001B[39minit\u001B[38;5;241m.\u001B[39mxavier_normal_(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvolutional1\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m)\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# self.convolutional1.apply(init_cnn)\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvolutional2 \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(\n\u001B[0;32m     33\u001B[0m     nn\u001B[38;5;241m.\u001B[39mConv2d(\u001B[38;5;241m32\u001B[39m,\u001B[38;5;241m32\u001B[39m,kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, bias\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[0;32m     34\u001B[0m     nn\u001B[38;5;241m.\u001B[39mBatchNorm2d(\u001B[38;5;241m32\u001B[39m),\n\u001B[0;32m     35\u001B[0m     nn\u001B[38;5;241m.\u001B[39mReLU(),\n\u001B[0;32m     36\u001B[0m     nn\u001B[38;5;241m.\u001B[39mMaxPool2d(\u001B[38;5;241m3\u001B[39m,\u001B[38;5;241m2\u001B[39m),\n\u001B[0;32m     37\u001B[0m )         \n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_cuda__118\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1614\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   1615\u001B[0m     \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Sequential' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "# import VizdoomEnv  # Import the VizdoomEnv module\n",
    "from vizdoom.gym_wrapper.gym_env_defns import VizdoomScenarioEnv\n",
    "from image_preprocessing import PreprocessImage\n",
    "\n",
    "doom_env = VizdoomScenarioEnv(\n",
    "    scenario_file='deadly_corridor.cfg',  # Specify the path to your scenario file\n",
    "    frame_skip=4,  # Adjust the frame skip if needed\n",
    "    max_buttons_pressed=1,  # Adjust the max buttons pressed if needed\n",
    "    render_mode='human'  # Set the render mode (either 'human' or 'rgb_array')\n",
    ")\n",
    "\n",
    "doom_env = PreprocessImage(doom_env, width = 80, height = 80, grayscale = True)\n",
    "# doom_env = gym.wrappers.ResizeObservation(doom_env, (80, 80))\n",
    "# doom_env = gym.wrappers.GrayScaleObservation(doom_env)\n",
    "doom_env = gym.wrappers.RecordVideo(doom_env, \"videos/doom.mp4\")\n",
    "number_actions = doom_env.action_space.n\n",
    "\n",
    "# Building the AI\n",
    "cnn = CNN(number_actions)\n",
    "softmax_body = SoftmaxBody(T = 1.0)\n",
    "\n",
    "ai = AI(brain=cnn, body=softmax_body)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T15:41:25.396360700Z",
     "start_time": "2023-10-12T15:41:24.387144Z"
    }
   },
   "id": "6927cbf4bbd69652"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11, 12, 13]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(np.linspace(1, 10, 10))\n",
    "a += [11,12,13]\n",
    "a"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-12T15:43:11.368526800Z",
     "start_time": "2023-10-12T15:43:11.354529500Z"
    }
   },
   "id": "3389d73e9b848ae6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
